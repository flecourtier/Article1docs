:stem: latexmath
# Cas test 7 - SquareDonut + Poisson modifié + Neumann
:training_dir: training/

On considère le problème de Poisson modifié avec conditions de Neumann défini par

[stem]
++++
\left\{
\begin{aligned}
-\Delta u + u &= f, \; &&\text{dans } \; \Omega, \\
\frac{\partial u}{\partial n}&=h_E, \; &&\text{sur } \; \Gamma_E, \\
\frac{\partial u}{\partial n}&=h_I, \; &&\text{sur } \; \Gamma_I.
\end{aligned}
\right.
++++

On définit stem:[\Omega] comme étant un "squaredonut" défini par
[stem]
++++
\Omega = [-1,1]^2 \backslash [-0.5,0.5]^2
++++

image::bc/testcase7.png[width=260.0,height=140.0]

On considèrera la solution analytique stem:[u_{ex}] définie par
[stem]
++++
u_{ex}(x,y)=\sin(2\pi x)\sin(2\pi y)
++++
et le second membre stem:[f] associé, défini par
[stem]
++++
f(x,y)=(1+8\pi^2)\sin(2\pi x)\sin(2\pi y)
++++

On définit alors les fonctions levelset respectives par
[stem]
++++
\phi_I(x,y)=\max(|x|,|y|)-0.5 \quad \text{et} \quad \phi_E(x,y)=\max(|x|,|y|)-1
++++

[NOTE]
.Fonction levelset normalisée
====
On remarquera que les levelsets considérées ici sont normalisées, plus précisément la norme de leur gradient est égale à 1 sur le bord du domaine. 
====

La fonction levelset est alors définie par
[stem]
++++
\phi(x,y)=\min(\phi_E,-\phi_I)
++++

On définit alors le réseau de neurones par
[stem]
++++
u_\theta(x,y)=w_{\theta,1}-\phi\nabla\phi\cdot\nabla w_{\theta,1} - \phi h + \phi**2 w_{\theta,2}
++++
avec 
[stem]
++++
h = h_E\frac{\phi_I^2}{\phi_I^2+\phi_E^2} + h_I\frac{\phi_E^2}{\phi_I^2+\phi_E^2}
++++
où stem:[w_{\theta,1}] et stem:[w_{\theta,2}] sont deux réseaus de neurones et 
[stem]
++++
h_E = 2\pi y\sin(2\pi x) + 2\pi x\sin(2\pi y) \quad \text{et} \quad h_I = 2h_E
++++